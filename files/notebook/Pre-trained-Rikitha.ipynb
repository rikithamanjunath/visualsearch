{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from glob import glob\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from PyInquirer import prompt, print_json\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.applications import ResNet50\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.python.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dir = '/visual/Semi_train'\n",
    "test_dir = '/visual/Semi_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful for getting number of files\n",
    "image_files = glob(training_dir + '/*/*.jp*g')\n",
    "test_image_files = glob(test_dir + '/*/*.jp*g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Classes = 11\n"
     ]
    }
   ],
   "source": [
    "# getting the number of classes i.e. type of fruits\n",
    "folders = glob(training_dir + '/*')\n",
    "num_classes = len(folders)\n",
    "print ('Total Classes = ' + str(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40264 images belonging to 11 classes.\n",
      "Found 11876 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = [64, 64]  \n",
    "training_datagen = ImageDataGenerator(horizontal_flip=True,\n",
    "                                   width_shift_range = 0.4,\n",
    "                                   height_shift_range = 0.4,\n",
    "                                   zoom_range=0.3,\n",
    "                                   rotation_range=20,\n",
    "                                   )\n",
    "test_datagen = ImageDataGenerator(horizontal_flip=True,\n",
    "                                   width_shift_range = 0.4,\n",
    "                                   height_shift_range = 0.4,\n",
    "                                   zoom_range=0.3,\n",
    "                                   rotation_range=20,\n",
    "                                   )\n",
    "\n",
    "training_generator = training_datagen.flow_from_directory(training_dir, target_size = IMAGE_SIZE, batch_size = 200, class_mode = 'categorical')\n",
    "test_generator = test_datagen.flow_from_directory(test_dir, target_size = IMAGE_SIZE, batch_size = 200, class_mode= 'categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_size = 224\n",
    "# batch_size = 10\n",
    "# train_generator = data_generator.flow_from_directory(\n",
    "#         '../input/flowers-recognition/flowers/flowers/',\n",
    "# #         target_size=(image_size, image_size),\n",
    "#         batch_size=batch_size,\n",
    "#         class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(ResNet50(include_top=False, pooling='avg', weights = 'imagenet'))\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "201/201 [==============================] - 1402s 7s/step - loss: 1.8999 - acc: 0.4110 - val_loss: 2.3199 - val_acc: 0.3951\n",
      "Epoch 2/5\n",
      "201/201 [==============================] - 1372s 7s/step - loss: 1.5465 - acc: 0.4540 - val_loss: 2.2330 - val_acc: 0.4219\n",
      "Epoch 3/5\n",
      "201/201 [==============================] - 1406s 7s/step - loss: 1.5172 - acc: 0.4613 - val_loss: 2.2271 - val_acc: 0.4254\n",
      "Epoch 4/5\n",
      "201/201 [==============================] - 1371s 7s/step - loss: 1.4969 - acc: 0.4682 - val_loss: 2.2990 - val_acc: 0.4322\n",
      "Epoch 5/5\n",
      "201/201 [==============================] - 1420s 7s/step - loss: 1.4830 - acc: 0.4722 - val_loss: 2.2686 - val_acc: 0.4345\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe5c27294a8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit_generator(training_generator,\n",
    "                              steps_per_epoch = 201, \n",
    "                              epochs = 5,\n",
    "                              validation_data = test_generator,\n",
    "                              validation_steps= 59)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = image.load_img('/visual/Semi_test/Dress/194_comsumer_03.jpg',target_size=(64,64));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = image.img_to_array(temp)\n",
    "temp = np.expand_dims(temp, axis=0)\n",
    "result = model.predict(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.1053301e-02, 3.0324402e-01, 3.6815446e-02, 4.1328077e-03,\n",
       "        5.2279621e-01, 6.0268089e-02, 1.9336292e-04, 1.9746641e-02,\n",
       "        2.7101650e-03, 1.1775832e-03, 2.7862413e-02]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Chiffon': 0,\n",
       " 'Dress': 1,\n",
       " 'Jeans': 2,\n",
       " 'Lace_Dress': 3,\n",
       " 'Lace_Shirt': 4,\n",
       " 'Leggings_and_Jeans': 5,\n",
       " \"Men's_Coats\": 6,\n",
       " \"Men's_Pants\": 7,\n",
       " \"Men's_Shirts\": 8,\n",
       " \"Men's_Summer_Wear\": 9,\n",
       " \"Men's_T_Shirt\": 10}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"/visual/Result/ResNet50-New.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
