{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Reference: https://www.kaggle.com/dansbecker/transfer-learning\n",
    "# importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import keras\n",
    "\n",
    "from glob import glob\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPool2D,Flatten,Dense,Dropout\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chiffon', 'Jeans', 'Lace_Dress', \"Men's_Shirts\", 'Skirt']\n"
     ]
    }
   ],
   "source": [
    "# loading the directories \n",
    "training_dir = 'C:/Users/avadh/Desktop/CMPE 295A/Dataset/Temp/Semi_Train'\n",
    "test_dir = 'C:/Users/avadh/Desktop/CMPE 295A/Dataset/Temp/Semi_Test'\n",
    "folders=os.listdir(\"C:/Users/avadh/Desktop/CMPE 295A/Dataset/Temp/Semi_Train\")\n",
    "print(folders)\n",
    "#test_dir = '../input/fruits/fruits-360_dataset/fruits-360/test-multiple_fruits/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=64,64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful for getting number of files\n",
    "image_files = glob(training_dir + '/*/*.jp*g')\n",
    "test_image_files = glob(test_dir + '/*/*.jp*g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train=[]\n",
    "image_labels=[]\n",
    "image_names=[]\n",
    "\n",
    "for folder in folders:\n",
    "    for each in os.listdir(os.path.join(training_dir,folder)):\n",
    "        if each.endswith('jpg'):\n",
    "            image_names.append(os.path.join(training_dir,folder,each))\n",
    "            image_labels.append(folder)\n",
    "            img=cv2.imread(os.path.join(training_dir,folder,each))\n",
    "            img_in=cv2.resize(img,size)\n",
    "            image_train.append(img_in)\n",
    "        else:\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_list=list(zip(image_train,image_labels))\n",
    "random.shuffle(union_list)\n",
    "train,labels=zip(*union_list)\n",
    "X=np.array(train)\n",
    "Y=np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X/255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()\n",
    "Y=le.fit_transform(Y)\n",
    "Y=to_categorical(Y,num_classes=len(folders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,Y_train,Y_val=train_test_split(X,Y,test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avadh\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "resnet_model=ResNet50(include_top=False,input_tensor=keras.engine.input_layer.Input(shape=(64, 64, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(resnet_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096,activation='relu'))\n",
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(len(folders),activation='softmax'))\n",
    "\n",
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 2, 2, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              33558528  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 20485     \n",
      "=================================================================\n",
      "Total params: 73,948,037\n",
      "Trainable params: 50,360,325\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=RMSprop(lr=0.0001)   #,rho=0.9,epsilon=1e-08,decay=0.0)\n",
    "model.compile(optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "learning_rate_reduction=ReduceLROnPlateau(monitor='val_acc',patience=3,verbose=1,factor=0.5,minlr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  \n",
    "        samplewise_center=False,  \n",
    "        featurewise_std_normalization=False,  \n",
    "        samplewise_std_normalization=False,  \n",
    "        zca_whitening=False,\n",
    "        rotation_range=10,  \n",
    "        zoom_range = 0.1, \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,  \n",
    "        horizontal_flip=False,\n",
    "        vertical_flip=False) \n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "536/535 [==============================] - 1450s 3s/step - loss: 1.8620 - acc: 0.4732 - val_loss: 1.8263 - val_acc: 0.3742\n",
      "Epoch 2/5\n",
      "536/535 [==============================] - 1109s 2s/step - loss: 1.4475 - acc: 0.5534 - val_loss: 1.9109 - val_acc: 0.3742\n",
      "Epoch 3/5\n",
      "536/535 [==============================] - 1161s 2s/step - loss: 1.2946 - acc: 0.5863 - val_loss: 2.2104 - val_acc: 0.3054\n",
      "Epoch 4/5\n",
      "536/535 [==============================] - 1516s 3s/step - loss: 1.2380 - acc: 0.6073 - val_loss: 1.8124 - val_acc: 0.3054\n",
      "Epoch 5/5\n",
      "536/535 [==============================] - 1529s 3s/step - loss: 1.1714 - acc: 0.6153 - val_loss: 1.8996 - val_acc: 0.3070\n"
     ]
    }
   ],
   "source": [
    "history=model.fit_generator(datagen.flow(X_train,Y_train,batch_size=10),epochs=5,validation_data=(X_val,Y_val),\n",
    "                          verbose=1,steps_per_epoch=X_train.shape[0]/10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"Dataset/MyVersion/ResNet50.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
